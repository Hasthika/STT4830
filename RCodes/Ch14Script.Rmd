---
title:  "Chapter 14 – Logistic Regression, Poisson Regression, and Generalized Linear Models"
author: Dr. Hasthika Rupasinghe
date: "Nov 14, 2023"
output:
  rmdformats::readthedown:
    toc_depth: 3
---

```{r setup, include=FALSE, comment=NA, warning=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Getting data -- Programming Task Example (examples 3 and 4 in the note)

```{r comment=NA, warning=FALSE, message=FALSE}
progTaskData <- read.table("http://www.cnachtsheim-text.csom.umn.edu/Kutner/Chapter%2014%20Data%20Sets/CH14TA01.txt", sep ="" , header = FALSE)
progTaskData
progTaskData <- progTaskData[,1:2] # Remove the last column to make the data set more practical

#Look at the first 6 entries
head(progTaskData)

names(progTaskData) <- c( "X" , "Y")
head(progTaskData)
```




### Scatter plot of the data and lowess fit

Example 3 part 1 and 2

```{r}
library(ggplot2)
library(cowplot)

sp <- ggplot(progTaskData, aes(x = X, y = Y)) + geom_point(color = "steelblue") + theme_bw() 
sp
lf <- ggplot(progTaskData, aes(x = X, y = Y)) + geom_point(color = "steelblue") + theme_bw() +
  geom_smooth(method = "loess",  se = FALSE, color = "red") 

plot_grid(sp, lf)


```



### Scatter plot with Lowess and logistic mean response functions

Example 3 part 4

```{r comment=NA, warning=FALSE, message=FALSE}

ggplot(progTaskData, aes(x = X, y = Y)) + geom_point(color = "steelblue") + theme_bw() +
  geom_smooth(method = "loess",  se = FALSE, color = "red") + 
  geom_smooth(method = "glm", method.args = list(family = "binomial"), se = FALSE, color = "steelblue")

```

### Fit a  logistic regression model

Example 3 part 5 and 6

Estimated Logistic Mean Response Function–Programming Task Example

```{r comment=NA, warning=FALSE, message=FALSE}
?glm
logitfit <- glm(Y ~ X, family = binomial(link = "logit"), progTaskData)
summary(logitfit)

# Fitted values

progTaskData
logitfit$fitted.values # This gives fitted values from the model for each case
cbind(progTaskData, 'fitted' = logitfit$fitted.values) # Table to make it easier to read

```

### Odds ratio

Example 4 part 1

```{r comment=NA, warning=FALSE, message=FALSE}

OR <- exp(coef(logitfit)[2]) # you can also do exp(0.16149) by using summary(logitfit) output
OR
```

***

## Repeat Observations-Binomial Outcomes

```{r comment=NA, warning=FALSE, message=FALSE}
CouponData <- read.table("http://www.cnachtsheim-text.csom.umn.edu/Kutner/Chapter%2014%20Data%20Sets/CH14TA02.txt", sep ="" , header = FALSE)
head(CouponData)

CouponData <- CouponData[,1:3] # Remove the last column to make the data set more practical

#Look at the first 6 entries
head(CouponData)

names(CouponData) <- c( "X", "n" , "Y")
head(CouponData)
```


### Example 5 part 1 

```{r comment=NA, warning=FALSE, message=FALSE}
y <- c(rep(1, sum(CouponData$Y)), rep(0, 1000 - sum(CouponData$Y)))
y
x <- c(rep(CouponData$X, CouponData$Y), rep(CouponData$X, 200 - CouponData$Y))
x

newCouponData <- data.frame(y, x)
head(newCouponData)
```


### Example 5 part 2

```{r comment=NA, warning=FALSE, message=FALSE}

modelRep <- glm(y ~ x, family = binomial(link = 'logit'), data = newCouponData)
summary(modelRep)
```

### Example 5 part 4

```{r comment=NA, warning=FALSE, message=FALSE}

library(dplyr)
newCouponData_p <- newCouponData %>%
  group_by(x) %>%
  summarize(p=mean(y))

newCouponData_p
```



### Example 5 part 5

```{r comment=NA, warning=FALSE, message=FALSE}
library(ggplot2)
ggplot(data = newCouponData_p, aes(x = x, y = p)) + geom_point()+
geom_smooth(method = "glm", method.args = list(family = "binomial"), se = FALSE, color = "steelblue") + theme_bw()
```


### Example 5 part 6

```{r comment=NA, warning=FALSE, message=FALSE}
OR <- exp(coef(modelRep)[2]) # you can also do exp(0.096834)
OR
```


***

## Disease Outbreak Example (Portion of Model-Building Data Set).

### Example 6 part 1

```{r comment=NA, warning=FALSE, message=FALSE}
DiseaseData <- read.table("http://www.cnachtsheim-text.csom.umn.edu/Kutner/Chapter%2014%20Data%20Sets/CH14TA03.txt", sep ="" , header = FALSE)
head(DiseaseData)
dim(DiseaseData)

DiseaseData <- DiseaseData[,-1] # Remove the 'case' column

#Look at the first 6 entries
head(DiseaseData)

# Rename columns
names(DiseaseData) <- c( "x1", "x2" , "x3", "x4", "y")
head(DiseaseData)

# Fitting the logistic model
DiseaseModel <- glm(y ~ x1 + x2 + x3 + x4, data = DiseaseData, family = binomial(link = 'logit'))
summary(DiseaseModel)
```

### Example 6 part 3

```{r comment=NA, warning=FALSE, message=FALSE}
# Odds ratio
OR1 <- exp(coef(DiseaseModel)) # Or find them individually, ex odds ratio for x1 is  exp(coef(DiseaseModel)[2]) 
OR1
```


### Example 6 part 5

```{r comment=NA, warning=FALSE, message=FALSE}

# Fitted values
DiseaseModel$fitted.values # This gives fitted values from the model for each case
cbind(DiseaseData, 'fitted' = DiseaseModel$fitted.values) # Table to make it easier to read
```



## Test Concerning a Single $\beta_k$: Wald Test
### Example 7 in the lecture note

Consider Programming Task Example

```{r}
summary(logitfit)
```

### Example 8 in the lecture note
```{r}

confint.default(logitfit, level = 0.95 )

#exp(logitfit$coefficients)         # exponentiated coefficients (odds ratio)
exp(confint.default(logitfit))     # 95% CI for exponentiated coefficients (odds ratio)


```


## Example 9 -Ltikelihood Ratio test

```{r}
library(lmtest)
DiseaseModelFull <- glm(y ~ x1 + x2 + x3 + x4, data = DiseaseData, family = binomial(link = 'logit')) # We got this model earlier

DiseaseModelReduced <- glm(y ~ x2 + x3 + x4, data = DiseaseData, family = binomial(link = 'logit'))

lrtest(DiseaseModelFull, DiseaseModelReduced)
```

## Example 10 (Best subsets procedures)


```{r warning=FALSE}
library(olsrr)
# To obtain the set of plots in page 362 
DiseaseModelAll <- lm(y ~ x1 + x2 + x3 + x4, data = DiseaseData)

obj2 <- ols_step_all_possible(DiseaseModelAll)
obj2 # Default table
plot(obj2) # Plots

# Custom Tables (Ex: with AIC and SBC)
tabAIC_SBC <- cbind(obj2$predictors, obj2$aic, obj2$sbc)
tabAIC_SBC <- data.frame(tabAIC_SBC)
names(tabAIC_SBC) <- c("Predictors", "AIC", "SBC")
as.data.frame(tabAIC_SBC) 

#Find best four models for each criteria

# Sort by AIC
tabAIC_SBC[order(tabAIC_SBC$AIC),]

# Sort by SBC
tabAIC_SBC[order(tabAIC_SBC$SBC),]
```



## Pearson Chi-Square Goodness of Fit Test


```{r comment=NA, warning=FALSE, message=FALSE}
CouponData <- read.table("http://www.cnachtsheim-text.csom.umn.edu/Kutner/Chapter%2014%20Data%20Sets/CH14TA02.txt", sep ="" , header = FALSE)
head(CouponData)

CouponData <- CouponData[,1:3] # Remove the last column to make the data set more practical

#Look at the first 6 entries
head(CouponData)

names(CouponData) <- c( "X", "n" , "Y")
head(CouponData)

y <- c(rep(1, sum(CouponData$Y)), rep(0, 1000 - sum(CouponData$Y)))
y
x <- c(rep(CouponData$X, CouponData$Y), rep(CouponData$X, 200 - CouponData$Y))
x

newCouponData <- data.frame(y, x)
head(newCouponData)

modelRep <- glm(y ~ x, family = binomial(link = 'logit'), data = newCouponData)
summary(modelRep)

obs_exp <- data.frame(fits = modelRep$fitted.values, xlevels = newCouponData$x, yvals = newCouponData$y)
obs_exp


# For y = 1
obs_exp_group_cou_red <- obs_exp %>%
   group_by(xlevels) %>%
  summarize(ni = n(), Pihat = mean(fits), Obs_cou_red = sum(yvals), Exp_cou_red = ni*Pihat)

obs_exp_group_cou_red

# For y = 0
obs_exp_group_cou_not_red <- obs_exp %>%
   group_by(xlevels) %>%
  summarize(ni = n(), Pihat = mean(fits), Obs_cou_not_red = 200-sum(yvals), Exp_cou_not_red = ni*(1-Pihat))

obs_exp_group_cou_not_red


chiSq1 <- (obs_exp_group_cou_red$Obs_cou_red - obs_exp_group_cou_red$Exp_cou_red)^2/obs_exp_group_cou_red$Exp_cou_red 
chiSq1

chiSq2 <- (obs_exp_group_cou_not_red$Obs_cou_not_red - obs_exp_group_cou_not_red$Exp_cou_not_red)^2/obs_exp_group_cou_not_red$Exp_cou_not_red
chiSq2

ChiSquareTestStat <- sum(chiSq1) + sum(chiSq2)
ChiSquareTestStat

df <- 5 - 2 # df = number of classes - number of parameters in the model
p_value <- 1-pchisq(ChiSquareTestStat, 3)
p_value
```

## Prediction of a New Observation

```{r comment=NA, warning=FALSE, message=FALSE}
DiseaseData <- read.table("http://www.cnachtsheim-text.csom.umn.edu/Kutner/Chapter%2014%20Data%20Sets/CH14TA03.txt", sep ="" , header = FALSE)
head(DiseaseData)
dim(DiseaseData)

DiseaseData <- DiseaseData[,-1] # Remove the 'case' column

#Look at the first 6 entries
head(DiseaseData)

# Rename columns
names(DiseaseData) <- c( "x1", "x2" , "x3", "x4", "y")
head(DiseaseData)

# Fitting the logistic model
DiseaseModel <- glm(y ~ x1 + x2 + x3 + x4, data = DiseaseData, family = binomial(link = 'logit'))
summary(DiseaseModel)


obs_Pi <- data.frame(Pi = DiseaseModel$fitted.values, disease_status = DiseaseModel$y)
obs_Pi

# Zeros #################################
correct0 <- obs_Pi %>%
  filter(Pi < .316) %>%
  filter(disease_status == 0)

n_correct0 <- nrow(correct0)
n_correct0

incorrect0 <- obs_Pi %>%
  filter(Pi < .316) %>%
  filter(disease_status == 1)

n_incorrect0 <- nrow(incorrect0)
n_incorrect0

# Ones #################################
correct1 <- obs_Pi %>%
  filter(Pi >= .316) %>%
  filter(disease_status == 1)

n_correct1 <- nrow(correct1)
n_correct1

incorrect1 <- obs_Pi %>%
  filter(Pi >= .316) %>%
  filter(disease_status == 0)

n_incorrect1 <- nrow(incorrect1)
n_incorrect1

# Making a classification table  #################################
classifi_table <- matrix(c(n_correct0, n_incorrect0, n_incorrect1 , n_correct1), nrow = 2)
#classifi_table

rownames(classifi_table) <- c("Y = 0", "Y = 1")
colnames(classifi_table) <- c("Yhat = 0", "Yhat = 1")

as.data.frame(classifi_table)


```


# Poisson Regression

## Miller Lumber Company Example.

```{r comment=NA, warning=FALSE, message=FALSE}
LumberData <- read.table("http://www.cnachtsheim-text.csom.umn.edu/Kutner/Chapter%2014%20Data%20Sets/CH14TA14.txt", sep ="" , header = FALSE)
head(LumberData)
dim(LumberData)


# Rename columns
names(LumberData) <- c( "y", "x1", "x2" , "x3", "x4", "x5")
head(LumberData)

# Fitting the poisson regression model
options(scipen = 999) # You can turn off the Scientific notation with options(scipen = 999) and back on again with options(scipen = 0)

LumberModel <- glm(y ~ x1 + x2 + x3 + x4 + x5, data = LumberData, family = poisson(link = 'log'))
summary(LumberModel)
```

